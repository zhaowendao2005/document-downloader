---
url: https://js.langchain.com.cn/docs/modules/memory/examples/redis
crawled_at: 2025-06-22T02:00:25.086954
---

基于Redis的聊天存储
如果需要在聊天会话之间进行长期持久化，可以将默认的内存
chatHistory
替换为一个
Redis
实例来支持聊天存储类，如
BufferMemory
。
设置
​
您需要在项目中安装
node-redis
。
npm
Yarn
pnpm
npm
install
redis
yarn
add
redis
pnpm
add
redis
您还需要一个Redis实例来连接。请参阅
Redis官方网站
上运行本地服务器的说明。
用法
​
Redis中存储的每个聊天历史记录会话都必须具有唯一的ID。你可以提供一个可选的
sessionTTL
参数来使会话在一定时间后过期。
传递给
createClient
方法的
config
参数直接传递给
node-redis
，并使用所有相同的参数。
import
{
BufferMemory
}
from
"langchain/memory"
;
import
{
RedisChatMessageHistory
}
from
"langchain/stores/message/redis"
;
import
{
ChatOpenAI
}
from
"langchain/chat_models/openai"
;
import
{
ConversationChain
}
from
"langchain/chains"
;
const
memory
=
new
BufferMemory
(
{
chatHistory
:
new
RedisChatMessageHistory
(
{
sessionId
:
new
Date
(
)
.
toISOString
(
)
,
// Or some other unique identifier for the conversation
sessionTTL
:
300
,
// 5 minutes, omit this parameter to make sessions never expire
config
:
{
url
:
"redis://localhost:6379"
,
// Default value, override with your own instance's URL
}
,
}
)
,
}
)
;
const
model
=
new
ChatOpenAI
(
{
modelName
:
"gpt-3.5-turbo"
,
temperature
:
0
,
}
)
;
const
chain
=
new
ConversationChain
(
{
llm
:
model
,
memory
}
)
;
const
res1
=
await
chain
.
call
(
{
input
:
"Hi! I'm Jim."
}
)
;
console
.
log
(
{
res1
}
)
;
/*
{
res1: {
text: "Hello Jim! It's nice to meet you. My name is AI. How may I assist you today?"
}
}
*/
const
res2
=
await
chain
.
call
(
{
input
:
"What did I just say my name was?"
}
)
;
console
.
log
(
{
res2
}
)
;
/*
{
res1: {
text: "You said your name was Jim."
}
}
*/
高级用法
​
您也可以直接传递先前创建的
node-redis
客户端实例:
import
{
createClient
}
from
"redis"
;
import
{
BufferMemory
}
from
"langchain/memory"
;
import
{
RedisChatMessageHistory
}
from
"langchain/stores/message/redis"
;
import
{
ChatOpenAI
}
from
"langchain/chat_models/openai"
;
import
{
ConversationChain
}
from
"langchain/chains"
;
const
client
=
createClient
(
{
url
:
"redis://localhost:6379"
,
}
)
;
const
memory
=
new
BufferMemory
(
{
chatHistory
:
new
RedisChatMessageHistory
(
{
sessionId
:
new
Date
(
)
.
toISOString
(
)
,
sessionTTL
:
300
,
client
,
}
)
,
}
)
;
const
model
=
new
ChatOpenAI
(
{
modelName
:
"gpt-3.5-turbo"
,
temperature
:
0
,
}
)
;
const
chain
=
new
ConversationChain
(
{
llm
:
model
,
memory
}
)
;
const
res1
=
await
chain
.
call
(
{
input
:
"Hi! I'm Jim."
}
)
;
console
.
log
(
{
res1
}
)
;
/*
{
res1: {
text: "Hello Jim! It's nice to meet you. My name is AI. How may I assist you today?"
}
}
*/
const
res2
=
await
chain
.
call
(
{
input
:
"What did I just say my name was?"
}
)
;
console
.
log
(
{
res2
}
)
;
/*
{
res1: {
text: "You said your name was Jim."
}
}
*/