---
url: https://js.langchain.com.cn/docs/modules/agents/agents/action/chat_mrkl
crawled_at: 2025-06-22T02:00:19.916971
---

MRKL聊天模型代理
这个例子介绍了如何使用一个使用ReAct框架(基于工具描述)来决定采取什么行动的代理。该代理被优化为在聊天模型中使用。如果您想在LLM中使用它，您可以使用
LLM MRKL代理
。
import
{
initializeAgentExecutorWithOptions
}
from
"langchain/agents"
;
import
{
ChatOpenAI
}
from
"langchain/chat_models/openai"
;
import
{
SerpAPI
}
from
"langchain/tools"
;
import
{
Calculator
}
from
"langchain/tools/calculator"
;
export
const
run
=
async
(
)
=>
{
const
model
=
new
ChatOpenAI
(
{
temperature
:
0
}
)
;
const
tools
=
[
new
SerpAPI
(
process
.
env
.
SERPAPI_API_KEY
,
{
location
:
"Austin,Texas,United States"
,
hl
:
"en"
,
gl
:
"us"
,
}
)
,
new
Calculator
(
)
,
]
;
const
executor
=
await
initializeAgentExecutorWithOptions
(
tools
,
model
,
{
agentType
:
"chat-zero-shot-react-description"
,
returnIntermediateSteps
:
true
,
}
)
;
console
.
log
(
"Loaded agent."
)
;
const
input
=
`
Who is Olivia Wilde's boyfriend? What is his current age raised to the 0.23 power?
`
;
console
.
log
(
`
Executing with input "
${
input
}
"...
`
)
;
const
result
=
await
executor
.
call
(
{
input
}
)
;
console
.
log
(
`
Got output
${
result
.
output
}
`
)
;
console
.
log
(
`
Got intermediate steps
${
JSON
.
stringify
(
result
.
intermediateSteps
,
null
,
2
)
}
`
)
;
}
;