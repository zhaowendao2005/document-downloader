---
url: https://js.langchain.com.cn/docs/modules/indexes/retrievers/vespa-retriever
crawled_at: 2025-06-22T02:00:23.527896
---

Vespa Retriever
展示如何使用Vespa.ai作为LangChain检索器。
Vespa.ai是用于高效结构化文本和向量搜索的平台。
请参阅
Vespa.ai
获取更多信息。
以下设置了一个从Vespa文档搜索中获取结果的检索器:
import
{
VespaRetriever
}
from
"langchain/retrievers/vespa"
;
export
const
run
=
async
(
)
=>
{
const
url
=
"https://doc-search.vespa.oath.cloud"
;
const
query_body
=
{
yql
:
"select content from paragraph where userQuery()"
,
hits
:
5
,
ranking
:
"documentation"
,
locale
:
"en-us"
,
}
;
const
content_field
=
"content"
;
const
retriever
=
new
VespaRetriever
(
{
url
,
auth
:
false
,
query_body
,
content_field
,
}
)
;
const
result
=
await
retriever
.
getRelevantDocuments
(
"what is vespa?"
)
;
console
.
log
(
result
)
;
}
;
此处，检索了"段落"文档类型中"内容"字段的最多5个结果，
使用"documentation"作为排名方法。"userQuery()"被实际查询替换
请参阅
pyvespa文档
获取更多信息。
URL是Vespa应用程序的终端点。
您可以连接任何Vespa终节点，远程服务或使用Docker本地实例。
然而，大多数Vespa Cloud实例都受到mTLS保护。
如果您的情况是这样的，您可以，例如设置
CloudFlare Worker
其中包含连接到该实例所需的凭据。
Now you can return the results and continue using them in LangChain.